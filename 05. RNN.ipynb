{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions used.\n",
      "Numpy :1.13.1 \n",
      "Tensorflow :1.2.1\n"
     ]
    }
   ],
   "source": [
    "print 'Library versions used.'\n",
    "print 'Numpy :{} \\nTensorflow :{}'.format(np.version.version, tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size\n",
      "Training Data \t: 55000\n",
      "validation Data : 5000\n",
      "Testing Data \t: 10000\n"
     ]
    }
   ],
   "source": [
    "print 'Data Size'\n",
    "print 'Training Data \\t:', len(data.train.labels)\n",
    "print 'validation Data :', len(data.validation.labels)\n",
    "print 'Testing Data \\t:', len(data.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "image_size_flatten = image_size * image_size\n",
    "num_labels = 10\n",
    "hidden_dim =128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, image_size_flatten], name='x')\n",
    "y_true = tf.placeholder(tf.int32, [None, num_labels], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class input_layer(object):\n",
    "    def __init__(self, inpt, name):\n",
    "        with tf.name_scope(name):\n",
    "            \n",
    "            self.W = tf.Variable(tf.truncated_normal([image_size, hidden_dim], stddev=0.1), name='input_W')\n",
    "            self.b = tf.Variable(tf.truncated_normal([hidden_dim], stddev=0.1), name='input_b')\n",
    "\n",
    "            self.X = tf.reshape(inpt, [-1, image_size])\n",
    "\n",
    "            self.output = tf.matmul(self.X, self.W) + self.b  #[64*28, 128]\n",
    "\n",
    "#             self.output = tf.reshape(_output,[-1, hidden_dim])\n",
    "\n",
    "            tf.summary.histogram(\"weights\", self.W)\n",
    "            tf.summary.histogram(\"bias\", self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vanilla_RNN(object):\n",
    "    def __init__(self,inpt, name):\n",
    "        with tf.name_scope(name):\n",
    "            self.W = tf.Variable(tf.truncated_normal([hidden_dim, hidden_dim], stddev=0.1), name='RNN_W')\n",
    "#             self.b = tf.Variable(tf.random_normal([hidden_dim]), name='RNN_b')                \n",
    "\n",
    "            def forward_propagation(prev_state, inpt_t):\n",
    "                current_state = tf.nn.sigmoid(tf.matmul(prev_state, self.W) + inpt_t)\n",
    "                return current_state\n",
    "\n",
    "            _output1 = tf.scan(forward_propagation, inpt, initializer=tf.zeros([1, hidden_dim])) #[64*28, 128]\n",
    "            _output2 = tf.reshape(_output1, [-1, image_size, hidden_dim]) #[64, 28, 128]\n",
    "            _output3 = tf.transpose(_output2, [1, 0, 2]) #[28, 64, 128]\n",
    "            _output = tf.unstack(_output3) # [28, 64, 128]\n",
    "            self.output = _output[-1] #28 x [64, 128]\n",
    "\n",
    "            tf.summary.histogram(\"weights\", self.W)\n",
    "#             tf.summary.histogram(\"bias\", self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMcell(object):\n",
    "    def __init__(self, inpt, name):\n",
    "        with tf.name_scope(name):\n",
    "            \n",
    "            self.inpt = tf.reshape(inpt,[-1, image_size, hidden_dim])\n",
    "#             self.inpt = tf.unstack(_inpt, image_size, 1)\n",
    "            self.lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_dim)\n",
    "            all_state, states = tf.nn.dynamic_rnn(self.lstm_cell, self.inpt, dtype=tf.float32)        \n",
    "            self.output = states[-1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class output_layer(object):\n",
    "    def __init__(self, inpt, name):\n",
    "        with tf.name_scope(name):\n",
    "            self.W = tf.Variable(tf.truncated_normal([hidden_dim, num_labels], stddev=0.1), name='output_W')\n",
    "            self.b = tf.Variable(tf.truncated_normal([num_labels], stddev=0.1), name='output_b')\n",
    "            \n",
    "            self.output = tf.matmul(inpt, self.W) + self.b  #[64, 10]\n",
    "            \n",
    "            tf.summary.histogram(\"weights\", self.W)\n",
    "            tf.summary.histogram(\"bias\", self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn = 'LSTM'\n",
    "\n",
    "layer0 = input_layer(x, name='input_layer')\n",
    "\n",
    "if rnn == 'LSTM':\n",
    "    layer1 = LSTMcell(layer0.output, name='lstm_layer')\n",
    "else:\n",
    "    layer1 = vanilla_RNN(layer0.output, name='rnn_layer')\n",
    "\n",
    "layer2 = output_layer(layer1.output, name='output_layer')\n",
    "output = layer2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(output)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define name_scope\n",
    "with tf.name_scope('cost'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #add the parameter cost to summary\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define name_scope\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(y_pred_cls, tf.argmax(y_true, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #add accuracy to the summary\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify a directory to save the model and the parameters\n",
    "LOGDIR = '/tmp/mnist/lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt = tf.reshape(x, shape=[-1, image_size, image_size, 1])\n",
    "# Store 3 inputs in the summary\n",
    "tf.summary.image('input', inpt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "merged_summary = tf.summary.merge_all()\n",
    "embedding_var = tf.Variable(tf.zeros([1024, 128]), name=\"embedding\")\n",
    "\n",
    "# specify which values should be used for embedding - the last fully connected layer output.\n",
    "assignment = embedding_var.assign(layer1.output)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "#create an object for the embedding class in config.\n",
    "embedding = config.embeddings.add()\n",
    "#Give embedding tensor the name that we created for the embedding_var\n",
    "embedding.tensor_name = embedding_var.name\n",
    "#set metadata_path to Path for .tsv file containing the true labels\n",
    "embedding.metadata_path = os.path.join(os.getcwd(), 'data/labels_1024.tsv')\n",
    "#set sprite image_path\n",
    "embedding.sprite.image_path   = os.path.join(os.getcwd(),'data/sprite_1024.png')\n",
    "# Now since all images are passed in a single file we need to specify the dimension of\n",
    "# each image in that particular file so the the model can idetify them\n",
    "embedding.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "# create a write instance to save in a particular file.\n",
    "writer = tf.summary.FileWriter(LOGDIR)\n",
    "# write the computation graph to the file\n",
    "writer.add_graph(session.graph)\n",
    "tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epoch = 10\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def train(epoch=10, batch_size=64):\n",
    "    total_batch = math.ceil(float(len(data.train.images))/batch_size) \n",
    "    print '------------------TRAINING------------------'\n",
    "    for i in range(epoch):\n",
    "        avg_cost = 0\n",
    "\n",
    "        session.run(assignment, feed_dict={x: data.test.images[:1024], y_true: data.test.labels[:1024]})\n",
    "        saver.save(session, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "\n",
    "        for j in range(int(total_batch)):\n",
    "            x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "            \n",
    "            feed_dict = {x: x_batch, y_true: y_batch}\n",
    "            \n",
    "            # at each batch calculate the summary and write to file.\n",
    "            s = session.run(merged_summary, feed_dict)\n",
    "            writer.add_summary(s, i*(total_batch)+j)                        \n",
    "\n",
    "            _, c = session.run([optimizer, cost], feed_dict)                \n",
    "            avg_cost += c / total_batch \n",
    "        print 'Epoch :{0} completed. Error :{1}'.format(i+1, avg_cost)\n",
    "    print '-------------TRAINING COMPLETED-------------'    \n",
    "    # save the final model\n",
    "    saver.save(session, LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "Epoch :1 completed. Error :0.328166353012\n",
      "Epoch :2 completed. Error :0.10932832997\n",
      "Epoch :3 completed. Error :0.102883451398\n",
      "Epoch :4 completed. Error :0.0957934707573\n",
      "Epoch :5 completed. Error :0.0876532530175\n",
      "Epoch :6 completed. Error :0.0974973493273\n",
      "Epoch :7 completed. Error :0.109495447109\n",
      "Epoch :8 completed. Error :0.111430109272\n",
      "Epoch :9 completed. Error :0.10511852601\n",
      "Epoch :10 completed. Error :0.119582771611\n",
      "-------------TRAINING COMPLETED-------------\n"
     ]
    }
   ],
   "source": [
    "train(epoch=10, batch_size=batch_size)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Run `tensorboard --logdir=/tmp/mnist/lstm` in terminal and see the results in tensorboard.\n"
     ]
    }
   ],
   "source": [
    "print('Done training!')\n",
    "print('Run `tensorboard --logdir=%s` in terminal and see the results in tensorboard.' % LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
