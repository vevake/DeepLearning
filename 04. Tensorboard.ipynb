{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook shows how to make use of the tensorboard present in tensorflow. The below code is exactly same as the previous notebook where a CNN was implemented. So to proceed it is advised to be familiar with the previous notebook implementation.\n",
    "\n",
    "We will add those additional codes alone in this notebook and look to capture the parameters of the model and visualize it in tensorboard.\n",
    "\n",
    "Only the additional lines that we add compared to the previous notebook is alone explained in the comments in the appropriate places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "Tensorboard is a visualization tool that come with tensorflow installation. So no additional libraries are required to use this.\n",
    "\n",
    "The general idea is that we want to store all the parameter values in a file and later pass this file to tensorboard to visualize it.\n",
    "\n",
    "The parameters that we visualize generally in a model are its computaional graph, weights and biases of layers, cost, accuracy values over time and then also how the model learns the embeddings for a input.\n",
    "\n",
    "So anything that we wish to store should be given a name, so that we can identify it in visualization. The names can be anything but unique for each parameter. But it is always advised to use the naming convention for debugging purposes.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# os library is used to specify the directories. \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions used.\n",
      "Numpy :1.13.1 \n",
      "Tensorflow :1.2.1\n"
     ]
    }
   ],
   "source": [
    "print 'Library versions used.'\n",
    "print 'Numpy :{} \\nTensorflow :{}'.format(np.version.version, tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size\n",
      "Training Data \t: 55000\n",
      "validation Data : 5000\n",
      "Testing Data \t: 10000\n"
     ]
    }
   ],
   "source": [
    "print 'Data Size'\n",
    "print 'Training Data \\t:', len(data.train.labels)\n",
    "print 'validation Data :', len(data.validation.labels)\n",
    "print 'Testing Data \\t:', len(data.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image vector size : 784\n"
     ]
    }
   ],
   "source": [
    "print 'Training image vector size :', len(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels : 10\n",
      "Example of a label : [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print 'Number of labels :', len(data.train.labels[0])\n",
    "print 'Example of a label :', data.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.validation.cls = np.array([label.argmax() for label in data.validation.labels])\n",
    "data.test.cls = np.array([label.argmax() for label in data.test.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "image_size_flatten = image_size * image_size\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the inputs x and y_true should be given a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, image_size_flatten], name='x')\n",
    "y_true = tf.placeholder(tf.float32, [None, num_labels], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building the convolution layer \n",
    "1. Provide a name for it. pass the name as parameter as if we use two ConvLayer we can generate layers with different names by passing it as parameter.\n",
    "2. Any parameter of the model that we wish to visualize should be added to the tensorflow summary. Here for the ConvLayer we store the weights, biases and the activations.\n",
    "3. The weights and biases stores should be defined in a way that they belong to a particular layer or name scope. For this case we use a name_scope function in tensorflow that groups the following into a single name_scope. In simple words it is like saying they all belong to this name_scope or layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    def __init__(self, inpt, filter_size, num_input_channels, num_filters, strides=(1,1,1,1), \n",
    "                 padding='SAME', activation=tf.nn.sigmoid, name='conv'):\n",
    "        \n",
    "        # create name_scope\n",
    "        with tf.name_scope(name):\n",
    "            self.input = inpt            \n",
    "            filter_shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "            \n",
    "            # provide name to weights and biases\n",
    "            self.W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), dtype=tf.float32, name='W')\n",
    "            self.b = tf.Variable(tf.truncated_normal(filter_shape[-1:], stddev=0.1), dtype=tf.float32, name='b')\n",
    "            conv_output = tf.nn.conv2d(self.input, filter=self.W, strides=strides, padding=padding)\n",
    "            conv_output = conv_output + self.b\n",
    "            self.output = activation(conv_output) if activation is not None else conv_output\n",
    "            \n",
    "            self.params = [self.W, self.b]\n",
    "\n",
    "            # add the parameters to tensorflow summary\n",
    "            tf.summary.histogram(\"weights\", self.W)\n",
    "            tf.summary.histogram(\"biases\", self.b)\n",
    "            tf.summary.histogram(\"activation\", self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(object):\n",
    "    def __init__(self, inpt, shape):\n",
    "        self.input = inpt        \n",
    "        self.output = tf.reshape(self.input, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MaxPoolLayer(object):\n",
    "    def __init__(self, inpt, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding=\"SAME\"):\n",
    "        self.input = inpt\n",
    "        self.output = tf.nn.max_pool(self.input, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropoutLayer(object):\n",
    "    def __init__(self, inpt):\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.input = inpt\n",
    "        self.output = tf.nn.dropout(self.input, keep_prob=self.keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_size1 = 5 \n",
    "num_filters1 = 16\n",
    "filter_size2 = 5\n",
    "num_filters2 = 36\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorboard we can also check if the input passed is the right one. For our case the input is an image. So we store a sample of 3 images alone in the summary that are passed on as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt = tf.reshape(x, shape=[-1, image_size, image_size, num_channels])\n",
    "\n",
    "# Store 3 inputs in the summary\n",
    "tf.summary.image('input', inpt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now since the ConvLayer accepts name as parameter, add name while creating the layer\n",
    "layer0_conv = ConvLayer(inpt, filter_size=filter_size1, num_input_channels = num_channels,\n",
    "                        num_filters=num_filters1, strides=[1, 1, 1, 1],\n",
    "                        activation=tf.nn.relu, padding='SAME', name='conv0')\n",
    "layer0_pool = MaxPoolLayer(layer0_conv.output, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now since the ConvLayer accepts name as parameter, add name while creating the layer\n",
    "layer1_conv = ConvLayer(layer0_pool.output, filter_size=filter_size2, num_input_channels = num_filters1,\n",
    "                        num_filters=num_filters2, strides=[1, 1, 1, 1], \n",
    "                        activation=tf.nn.relu, padding=\"SAME\", name='conv1')\n",
    "layer1_pool = MaxPoolLayer(layer1_conv.output, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = layer1_pool.output.get_shape()[1:4].num_elements()\n",
    "layer2_flatten = FlattenLayer(layer1_pool.output, shape=[-1, num_features])\n",
    "layer2_dropout = DropoutLayer(layer2_flatten.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we do the same as we did for ConvLayer, define a name_scope and then add the parameters to the summary\n",
    "fc_size = 128\n",
    "#define name_scope\n",
    "with tf.name_scope('fc'):\n",
    "    weights_fc = tf.get_variable('fc_w', [num_features, fc_size], tf.float32)\n",
    "    biases_fc = tf.get_variable('fc_b', [fc_size], tf.float32)\n",
    "    fc_output = tf.nn.relu(tf.matmul(layer2_dropout.output, weights_fc) + biases_fc)\n",
    "    \n",
    "    # add weights and biases to summary\n",
    "    tf.summary.histogram('weights', weights_fc)\n",
    "    tf.summary.histogram('biases', biases_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define name_scope\n",
    "with tf.name_scope('output_layer'):\n",
    "    weights_output = tf.get_variable('output_w', [fc_size, num_labels], tf.float32)\n",
    "    biases_output = tf.get_variable('output_b', [num_labels], tf.float32)\n",
    "    output = tf.matmul(fc_output, weights_output) + biases_output\n",
    "    \n",
    "    # add weights and biases to summary\n",
    "    tf.summary.histogram('weights', weights_output)\n",
    "    tf.summary.histogram('biases', biases_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(output)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the cost function needs to visualized to check how the cost of the model varies over time. But previously the weights and biases we added to the summary are viewed as distributions but the cost is a scalar value. So we need to store it as scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define name_scope\n",
    "with tf.name_scope('cost'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #add the parameter cost to summary\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuray is another parameter that helps us understand if the model is working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define name_scope\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(y_pred_cls, tf.argmax(y_true, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #add accuracy to the summary\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify a directory to save the model and the parameters\n",
    "LOGDIR = '/tmp/mnist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we added different type of parameters to the summary like histogram and scalar, we need to tell tensorflow to store them together in a single file. It is done by merge_all function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define to store the embeddings that the model has learnt. For this we would pass the first 1024 test data and  visualize the embedding the model has learnt for those inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a tensor for the embedding for the embedding. \n",
    "# The shape is the number of images that we pass which in our case is 1024 to the size of last fully connected layer.\n",
    "# The reason for using the last fully connected layer is because it the point at which the model has \n",
    "# all features extracted and is to be passed onto the output layer.\n",
    "embedding_var = tf.Variable(tf.zeros([1024, fc_size]), name=\"embedding\")\n",
    "\n",
    "# specify which values should be used for embedding - the last fully connected layer output.\n",
    "assignment = embedding_var.assign(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While visualizing the embedding we would like to see them as images and the true labels of them displayed, so we can understand better how well the embedding is learnt. But so far we passed only the embedding values to disaply them, so to seem them as image instead of point being displayed in the embedding visualization we need to also tell the tensorboard the image and the true label of those data.\n",
    "\n",
    "For easier computations, tensorflow require to pass them as specific files. <br/>\n",
    "A .tsv file containing the true labels of those data. <br/>\n",
    "A sprite image file which contains all those images in a single file. <br/>\n",
    "(You can read more about those files in tensorflowwebsite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a projector config\n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "#create an object for the embedding class in config.\n",
    "embedding = config.embeddings.add()\n",
    "#Give embedding tensor the name that we created for the embedding_var\n",
    "embedding.tensor_name = embedding_var.name\n",
    "#set metadata_path to Path for .tsv file containing the true labels\n",
    "embedding.metadata_path = os.path.join(os.getcwd(), 'data/labels_1024.tsv')\n",
    "#set sprite image_path\n",
    "embedding.sprite.image_path   = os.path.join(os.getcwd(),'data/sprite_1024.png')\n",
    "# Now since all images are passed in a single file we need to specify the dimension of\n",
    "# each image in that particular file so the the model can idetify them\n",
    "embedding.sprite.single_image_dim.extend([28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set everything we need to visualize, we need to write them in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a write instance to save in a particular file.\n",
    "writer = tf.summary.FileWriter(LOGDIR)\n",
    "# write the computation graph to the file\n",
    "writer.add_graph(session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next line writes a projector_config.pbtxt in the LOGDIR. TensorBoard will read this file during startup.\n",
    "# This is a config file where the path of the sprite file, tsv file are specified the path\n",
    "tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoch = 10\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def train(epoch=10, batch_size=64):\n",
    "    total_batch = math.ceil(float(len(data.train.images))/batch_size) \n",
    "    print '------------------TRAINING------------------'\n",
    "    for i in range(epoch):\n",
    "        avg_cost = 0\n",
    "        # save the initial embeddings. we pass the first 1024 test data as input for the embedding \n",
    "        # with dropout probability set to 1.0\n",
    "        session.run(assignment, feed_dict={x: data.test.images[:1024], y_true: data.test.labels[:1024], layer2_dropout.keep_prob:1.0})\n",
    "        # save the initial model with i as suffix , so that we can keep track of the learning at different epoch\n",
    "        saver.save(session, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "\n",
    "        for j in range(int(total_batch)):\n",
    "            x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "            \n",
    "            feed_dict = {x: x_batch, y_true: y_batch, layer2_dropout.keep_prob:0.5}\n",
    "            \n",
    "            # at each batch calculate the summary and write to file.\n",
    "            s = session.run(merged_summary, feed_dict)\n",
    "            writer.add_summary(s, i*(total_batch)+j)                        \n",
    "\n",
    "            _, c = session.run([optimizer, cost], feed_dict)                \n",
    "            avg_cost += c / total_batch \n",
    "        print 'Epoch :{0} completed. Error :{1}'.format(i+1, avg_cost)\n",
    "    print '-------------TRAINING COMPLETED-------------'    \n",
    "    # save the final model\n",
    "    saver.save(session, LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "Epoch :1 completed. Error :0.218448304452\n",
      "Epoch :2 completed. Error :0.0743830678518\n",
      "Epoch :3 completed. Error :0.0593719641093\n",
      "Epoch :4 completed. Error :0.0471451916324\n",
      "Epoch :5 completed. Error :0.0416919785725\n",
      "Epoch :6 completed. Error :0.0365576494207\n",
      "Epoch :7 completed. Error :0.0318568797937\n",
      "Epoch :8 completed. Error :0.0288753090377\n",
      "Epoch :9 completed. Error :0.0262601324376\n",
      "Epoch :10 completed. Error :0.0234545576143\n",
      "-------------TRAINING COMPLETED-------------\n"
     ]
    }
   ],
   "source": [
    "train(epoch=10)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Run `tensorboard --logdir=/tmp/mnist/` in terminal and see the results in tensorboard.\n"
     ]
    }
   ],
   "source": [
    "print('Done training!')\n",
    "print('Run `tensorboard --logdir=%s` in terminal and see the results in tensorboard.' % LOGDIR)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
